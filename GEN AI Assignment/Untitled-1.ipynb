{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e6a81d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% \n",
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"YuvrajSingh9886/Agriculture-Soil-QA-Pairs-Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7b2ea5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Unnamed: 0', 'ANSWER', 'QUESTION.question', 'QUESTION.paragraph'],\n",
       "        num_rows: 3447\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %% \n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "284a99fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import evaluate\n",
    "import re\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    Seq2SeqTrainer,\n",
    "    DataCollatorForSeq2Seq\n",
    ")\n",
    "\n",
    "from transformers import pipeline\n",
    "from transformers import set_seed\n",
    "set_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e17e13de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Unnamed: 0', 'ANSWER', 'QUESTION.question', 'QUESTION.paragraph'],\n",
       "        num_rows: 2757\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Unnamed: 0', 'ANSWER', 'QUESTION.question', 'QUESTION.paragraph'],\n",
       "        num_rows: 690\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %% \n",
    "split_dataset = ds[\"train\"].train_test_split(test_size=0.2, seed=42)\n",
    "split_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "166999ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>question: What is often rewarded under agri-en...</td>\n",
       "      <td>Semi-natural habitats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>question: When can the harvesting process for ...</td>\n",
       "      <td>The harvesting process for these crops can gen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>question: What can help optimize nutrient cycl...</td>\n",
       "      <td>Variety and species mixtures (intercrops).</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>question: What is included in the assessment o...</td>\n",
       "      <td>Number of earthworm burrows and extent of visi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>question: How can soil-borne pest build-up ass...</td>\n",
       "      <td>Soil-borne pest build-up can be avoided by pra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2752</th>\n",
       "      <td>question: Why is it important to incorporate t...</td>\n",
       "      <td>To ensure minimal nitrogen loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2753</th>\n",
       "      <td>question: How do microbes contribute to nutrie...</td>\n",
       "      <td>Microbes contribute to nutrient availability b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2754</th>\n",
       "      <td>question: How does the hand texturing method c...</td>\n",
       "      <td>In the hand texturing method, soil that forms ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2755</th>\n",
       "      <td>question: List methods to minimize soil compac...</td>\n",
       "      <td>To minimize soil compaction from machinery, on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2756</th>\n",
       "      <td>question: Discuss the suitability of medium te...</td>\n",
       "      <td>Medium textured soils are widely acceptable fo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2757 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              questions  \\\n",
       "0     question: What is often rewarded under agri-en...   \n",
       "1     question: When can the harvesting process for ...   \n",
       "2     question: What can help optimize nutrient cycl...   \n",
       "3     question: What is included in the assessment o...   \n",
       "4     question: How can soil-borne pest build-up ass...   \n",
       "...                                                 ...   \n",
       "2752  question: Why is it important to incorporate t...   \n",
       "2753  question: How do microbes contribute to nutrie...   \n",
       "2754  question: How does the hand texturing method c...   \n",
       "2755  question: List methods to minimize soil compac...   \n",
       "2756  question: Discuss the suitability of medium te...   \n",
       "\n",
       "                                                answers  \n",
       "0                                 Semi-natural habitats  \n",
       "1     The harvesting process for these crops can gen...  \n",
       "2            Variety and species mixtures (intercrops).  \n",
       "3     Number of earthworm burrows and extent of visi...  \n",
       "4     Soil-borne pest build-up can be avoided by pra...  \n",
       "...                                                 ...  \n",
       "2752                    To ensure minimal nitrogen loss  \n",
       "2753  Microbes contribute to nutrient availability b...  \n",
       "2754  In the hand texturing method, soil that forms ...  \n",
       "2755  To minimize soil compaction from machinery, on...  \n",
       "2756  Medium textured soils are widely acceptable fo...  \n",
       "\n",
       "[2757 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %% \n",
    "questions = [\"question: \" + q for q in split_dataset['train']['QUESTION.question']]\n",
    "answers = [a for a in split_dataset['train']['ANSWER']]\n",
    "\n",
    "df = pd.DataFrame({'questions': questions, 'answers': answers})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9421b75c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f15851cd0d94a42af32cae018c39ee1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/82.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ayush\\anaconda3\\envs\\tf\\lib\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\ayush\\.cache\\huggingface\\hub\\models--google--mt5-small. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "030fec967a0e4a05baa6c33abbbbb6b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/553 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fee50ca7de0b47e5933b2a1a76249bf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/4.31M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3d72125f14d4a208350bf1ed686cfc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "c:\\Users\\ayush\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\convert_slow_tokenizer.py:560: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ada52ab73254b5e9d3fcfcdf06db4cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.20G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9de64577d09d404fa1aa623afad616b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "984d8e11ea8d4986b0c866b0a4f7f579",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2757 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59b0c8507a4d433c854c869a7fa2137f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/690 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %% \n",
    "# Use a fine-tuned agriculture-specific T5 model\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "model_name = \"google/mt5-small\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "# Ensure CUDA is used if available\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Define max lengths\n",
    "max_input_length = 256\n",
    "max_target_length = 64\n",
    "\n",
    "# Define the preprocessing function\n",
    "def preprocess(batch):\n",
    "    inputs = [\"question: \" + q.strip() for q in batch[\"QUESTION.question\"]]\n",
    "    targets = [a[0] if isinstance(a, list) else a for a in batch[\"ANSWER\"]]\n",
    "    \n",
    "    model_inputs = tokenizer(inputs, \n",
    "                             max_length=max_input_length, \n",
    "                             truncation=True, \n",
    "                             padding=True)\n",
    "    \n",
    "    labels = tokenizer(targets, \n",
    "                       max_length=max_target_length, \n",
    "                       truncation=True, \n",
    "                       padding=True)\n",
    "    \n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "# Apply the preprocessing\n",
    "train_dataset = split_dataset[\"train\"].map(preprocess, batched=True)\n",
    "test_dataset = split_dataset[\"test\"].map(preprocess, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88b9a381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% \n",
    "rouge = evaluate.load(\"rouge\")\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    if hasattr(preds, \"dim\"):\n",
    "        preds = preds.argmax(dim=-1)\n",
    "    else:\n",
    "        preds = np.argmax(preds, axis=-1)\n",
    "\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "\n",
    "    labels = [[(l if l != -100 else tokenizer.pad_token_id) for l in label] for label in labels]\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    decoded_preds = [\"\\n\".join(pred.strip().split(\". \")) for pred in decoded_preds]\n",
    "    decoded_labels = [\"\\n\".join(label.strip().split(\". \")) for label in decoded_labels]\n",
    "\n",
    "    result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "    \n",
    "    result = {key: round(value * 100, 4) for key, value in result.items()}\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95d52ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% \n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir = \"./t5-agri-qa\",\n",
    "    per_device_train_batch_size = 8,\n",
    "    gradient_accumulation_steps = 4,\n",
    "    num_train_epochs = 3,\n",
    "    learning_rate = 5e-5,\n",
    "    evaluation_strategy = \"epoch\",      \n",
    "    save_strategy = \"epoch\",             \n",
    "    logging_dir = \"./logs\",             \n",
    "    logging_steps = 10,\n",
    "    predict_with_generate = True,\n",
    "    fp16 = True,\n",
    "    save_total_limit = 2,\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model             = model,\n",
    "    args              = training_args,\n",
    "    train_dataset     = train_dataset,\n",
    "    eval_dataset      = test_dataset,\n",
    "    data_collator     = data_collator,\n",
    "    tokenizer         = tokenizer,\n",
    "    compute_metrics   = compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "564dc34a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "070d6248f7074a85ba7083a5975c237f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/258 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.12}\n",
      "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.23}\n",
      "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.35}\n",
      "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.46}\n",
      "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.58}\n",
      "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.7}\n",
      "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.81}\n",
      "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.93}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ayush\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\generation\\utils.py:1141: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa0e83633c0e4a41ace47f7215646619",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/87 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': nan, 'eval_rouge1': 0.0, 'eval_rouge2': 0.0, 'eval_rougeL': 0.0, 'eval_rougeLsum': 0.0, 'eval_runtime': 160.9356, 'eval_samples_per_second': 4.287, 'eval_steps_per_second': 0.541, 'epoch': 1.0}\n",
      "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.04}\n",
      "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.16}\n",
      "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.28}\n",
      "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.39}\n",
      "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.51}\n",
      "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.62}\n",
      "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.74}\n",
      "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.86}\n",
      "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 1.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ayush\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\generation\\utils.py:1141: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a789d35dabfe40febb9520bd4e72b412",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/87 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': nan, 'eval_rouge1': 0.0, 'eval_rouge2': 0.0, 'eval_rougeL': 0.0, 'eval_rougeLsum': 0.0, 'eval_runtime': 159.9271, 'eval_samples_per_second': 4.314, 'eval_steps_per_second': 0.544, 'epoch': 1.99}\n",
      "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.09}\n",
      "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.2}\n",
      "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.32}\n",
      "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.43}\n",
      "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.55}\n",
      "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.67}\n",
      "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.78}\n",
      "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 2.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ayush\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\generation\\utils.py:1141: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "299a3d529cf04554a4244e7b46217889",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/87 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': nan, 'eval_rouge1': 0.0, 'eval_rouge2': 0.0, 'eval_rougeL': 0.0, 'eval_rougeLsum': 0.0, 'eval_runtime': 239.9257, 'eval_samples_per_second': 2.876, 'eval_steps_per_second': 0.363, 'epoch': 2.99}\n",
      "{'train_runtime': 2292.9369, 'train_samples_per_second': 3.607, 'train_steps_per_second': 0.113, 'train_loss': 0.0, 'epoch': 2.99}\n"
     ]
    }
   ],
   "source": [
    "# %% \n",
    "trainer.train()\n",
    "trainer.save_model(\"./t5-agri-qa\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce226cc4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m         rougeL\u001b[38;5;241m.\u001b[39mappend(log[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meval_rougeL\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Plot\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m5\u001b[39m))\n\u001b[0;32m     21\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(epochs, rougeL, marker\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mo\u001b[39m\u001b[38;5;124m\"\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mROUGE-L Score\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     22\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mROUGE-L Score vs Epochs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# %% \n",
    "import json\n",
    "\n",
    "# Read all log files (they are saved in 'trainer_state.json')\n",
    "with open(\"t5-agri-qa/checkpoint-258/trainer_state.json\", \"r\") as f:\n",
    "    logs = json.load(f)\n",
    "\n",
    "training_logs = logs[\"log_history\"]\n",
    "\n",
    "# Extract rougeL scores and epochs\n",
    "epochs = []\n",
    "rougeL = []\n",
    "\n",
    "for log in training_logs:\n",
    "    if \"eval_rougeL\" in log:\n",
    "        epochs.append(log[\"epoch\"])\n",
    "        rougeL.append(log[\"eval_rougeL\"])\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(epochs, rougeL, marker=\"o\", label=\"ROUGE-L Score\")\n",
    "plt.title(\"ROUGE-L Score vs Epochs\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"ROUGE-L (%)\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
